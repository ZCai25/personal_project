{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://www.reddit.com/r/DnDBehindTheScreen/comments/4hhesq/10k_project_the_return_of_10000_things/\">Reddit DnDBehindTheScreen</a>\n",
      "<a href=\"./plothooks/\">Plot Hooks</a>\n",
      "<a href=\"./mysteries/\">Mysteries</a>\n",
      "<a href=\"./villains/\">Villains</a>\n",
      "<a href=\"./dungeons/\">Dungeons</a>\n",
      "<a href=\"./treasures/\">Treasures</a>\n",
      "<a href=\"./locations/\">Locations</a>\n",
      "<a href=\"./npcs/\">NPCs</a>\n",
      "<a href=\"./rooms/\">Rooms</a>\n",
      "<a href=\"./apocalypses/\">Apocalypses</a>\n",
      "<a href=\"./books/\">Books</a>\n",
      "<a href=\"./partyfoods/\">Party Foods</a>\n",
      "<a class=\"btn btn-default\" href=\"./npcs/\" role=\"button\">View NPCs »</a>\n",
      "<a class=\"btn btn-default\" href=\"./mysteries/\" role=\"button\">View Mysteries »</a>\n",
      "<a class=\"btn btn-default\" href=\"./locations/\" role=\"button\">View Locations »</a>\n",
      "<a class=\"btn btn-default\" href=\"./treasures/\" role=\"button\">View Treasures »</a>\n",
      "<a class=\"btn btn-default\" href=\"./dungeons/\" role=\"button\">View Dungeons »</a>\n",
      "<a class=\"btn btn-default\" href=\"./plothooks/\" role=\"button\">View Plot Hooks »</a>\n",
      "<a class=\"btn btn-default\" href=\"./villains/\" role=\"button\">View Villains »</a>\n",
      "<a class=\"btn btn-default\" href=\"./rooms/\" role=\"button\">View Rooms »</a>\n",
      "<a href=\"//reddit.com/r/DnDBehindTheScreen\">r/DnDBehindTheScreen</a>\n",
      "<a href=\"https://www.reddit.com/r/DnDBehindTheScreen/comments/3ez8tr/10000_compilation_lists/\">contribute</a>\n",
      "<a href=\"https://www.reddit.com/r/DnDBehindTheScreen/comments/3ez8tr/10000_compilation_lists/\">reddit threads</a>\n",
      "<a href=\"https://github.com/AnEmortalKid/anemortalkid.github.io\">the site repo</a>\n",
      "<a href=\"https://github.com/AnEmortalKid/reddit-parser\"> the code repo</a>\n",
      "<a href=\"//reddit.com/u/Crow1170\">/u/crow1170</a>\n",
      "<a href=\"//reddit.com/u/AnEmortalKid\">/u/AnEmortalKid</a>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "# scrape all the hyperlinks in the website that has the table and save them to {links}.csv  \n",
    "# Send a GET request to the homepage\n",
    "homepage_url = \"http://anemortalkid.github.io/dnd-index.html\"\n",
    "homepage_response = requests.get(homepage_url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "homepage_soup = BeautifulSoup(homepage_response.content, \"html.parser\")\n",
    "\n",
    "# Find all the links in the homepage\n",
    "links = homepage_soup.find_all(\"a\")\n",
    "\n",
    "# Loop through each link and check if it contains a table\n",
    "for link in links:\n",
    "    print(link)\n",
    "\n",
    "    url = link.get(\"href\")\n",
    "    # print(url)\n",
    "    if url is None:\n",
    "        continue\n",
    "    full_url = f\"http://anemortalkid.github.io/{url}\"\n",
    "    print(full_url)\n",
    "    # Send a GET request to the link\n",
    "    response = requests.get(full_url)\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Find the table element using its class name\n",
    "    table = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "    # If a table is found, extract its headers and data rows and save them to a CSV file\n",
    "    if table is not None:\n",
    "        # Extract the table headers and data rows\n",
    "        headers = [header.text for header in table.find_all(\"th\")]\n",
    "        data_rows = []\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            data_rows.append([data.text for data in row.find_all(\"td\")])\n",
    "\n",
    "        # Save the table to a CSV file\n",
    "        with open(f\"scrape_result/{url[2:-1]}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(headers)\n",
    "            writer.writerows(data_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
