{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import praw\n",
    "import datetime\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_definition import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def praw_setup(client_id, client_secret, user_agent, password, username):\n",
    "    '''\n",
    "    Instantiate the Python Reddit API Wrapper (PRAW)\n",
    "    object in order to access Reddit data.\n",
    "    \n",
    "    client_id = client_id from your app info on \n",
    "        Reddit's dev website\n",
    "    client_secret = client_secret from from your\n",
    "        app info on Reddit's dev website\n",
    "    user_agent = A string representing whoever is\n",
    "        accessing the data. Per Reddit's API rules,\n",
    "        must include your Reddit username.\n",
    "    password = Your reddit account's password.\n",
    "    username = Your reddit username.\n",
    "    '''\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=user_agent,\n",
    "        password=password,\n",
    "        username=username\n",
    "    )\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_post_titles_text_and_features(reddit, post_limit, timeframe='day', one_sub=False, sub=None):\n",
    "#     '''\n",
    "#     Obtain the top n (post_limit) posts in the requested \n",
    "#     timeframe on all 11 subreddits, as well as desired attributes. Can also specify if \n",
    "#     just want post info on one subreddit.\n",
    "    \n",
    "#     reddit = PRAW instance\n",
    "#     post_limit = # of posts you want to get\n",
    "#     timeframe = hour, day (the default), week, month, year, \n",
    "#         or all (which is all time)\n",
    "#     one_sub = If True, gathers data on specific subreddit.\n",
    "#     sub = Specific subreddit to get data.\n",
    "#     '''\n",
    "#     # regex_pattern = r'1\\.\\s.*\\n2\\.\\s.*'\n",
    "#     # regex = re.compile(regex_pattern, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "#     subreddits = ['RandomTables','BehindTheTables','d100']\n",
    "#     table = []\n",
    "#     for subreddit in subreddits:\n",
    "#         for submission in reddit.subreddit(subreddit).top(limit=post_limit, time_filter=timeframe):\n",
    "#             # if regex.search(submission.selftext):\n",
    "#             if 'table' in submission.title.lower() or 'table' in submission.selftext.lower():\n",
    "#                 table.append([submission.id,\n",
    "#                             submission.title,\n",
    "#                             submission.selftext, # get post text\n",
    "#                             submission.subreddit.display_name,\n",
    "#                             datetime.datetime.utcfromtimestamp(submission.created_utc),\n",
    "#                             submission.score,\n",
    "#                             submission.num_comments,\n",
    "#                             submission.total_awards_received])\n",
    "#     return pd.DataFrame(table, columns=['post_id', 'post_title', 'post_text', 'post_subreddit',\n",
    "#                                            'creation_datetime', 'score', 'num_comments', 'total_awards_received'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_titles_text_and_features(reddit, post_limit, timeframe='day', one_sub=False, sub=None):\n",
    "    '''\n",
    "    Obtain the top n (post_limit) posts in the requested \n",
    "    timeframe on all 11 subreddits, as well as desired attributes. Can also specify if \n",
    "    just want post info on one subreddit.\n",
    "    \n",
    "    reddit = PRAW instance\n",
    "    post_limit = # of posts you want to get\n",
    "    timeframe = hour, day (the default), week, month, year, \n",
    "        or all (which is all time)\n",
    "    one_sub = If True, gathers data on specific subreddit.\n",
    "    sub = Specific subreddit to get data.\n",
    "    '''\n",
    "    subreddits = ['DnD','RandomTables', 'BehindTheTables', 'd100']\n",
    "    keywords = ['table','random tables', 'table rolls', 'd100 tables', 'table generators', 'tabletop rpg tables',\n",
    "                'tabletop game tables', 'randomized tables', 'randomizer tables', 'table charts',\n",
    "                'tabletop game charts']\n",
    "\n",
    "    table = []\n",
    "    for subreddit in subreddits:\n",
    "        for submission in reddit.subreddit(subreddit).top(limit=post_limit, time_filter=timeframe):\n",
    "            title_lower = submission.title.lower() if submission.title else ''\n",
    "            selftext_lower = submission.selftext.lower() if submission.selftext else ''\n",
    "            if any(keyword in title_lower or keyword in selftext_lower for keyword in keywords):\n",
    "                table.append([\n",
    "                    submission.id,\n",
    "                    submission.title,\n",
    "                    submission.selftext,\n",
    "                    submission.subreddit.display_name,\n",
    "                    datetime.datetime.utcfromtimestamp(submission.created_utc),\n",
    "                    submission.score,\n",
    "                    submission.num_comments,\n",
    "                    submission.total_awards_received\n",
    "                ])\n",
    "    return pd.DataFrame(table, columns=['post_id', 'post_title', 'post_text', 'post_subreddit',\n",
    "                                        'creation_datetime', 'score', 'num_comments', 'total_awards_received'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_and_features(reddit, post_limit, timeframe='day', one_sub=False, sub=None):\n",
    "    \"\"\"\n",
    "    Obtain the top n posts' comments from 11 particular subreddits\n",
    "    in requested timeframe, as well as desired attributes.\n",
    "    \n",
    "    reddit = PRAW instance\n",
    "    post_limit = # of desired posts\n",
    "    timeframe = hour, day (the default), week, month, year, \n",
    "        or all (which is all time)\n",
    "    one_sub = If True, gathers data on specific subreddit.\n",
    "    sub = Specific subreddit to get data.\n",
    "    \"\"\"\n",
    "    if one_sub == True:\n",
    "        table = []\n",
    "        for submission in reddit.subreddit(sub).top(limit=post_limit, time_filter=timeframe):\n",
    "            comments = submission.comments[:-1] # not taking into account the MoreComments object\n",
    "            for comment in comments:\n",
    "                match = re.search(r'\\b\\d+d\\d+\\b', comment.body) # Search for pattern\n",
    "                if match:\n",
    "                    table.append([submission.id,\n",
    "                                  comment.id,\n",
    "                                  comment.body,\n",
    "                                  submission.subreddit.display_name,\n",
    "                                  datetime.datetime.utcfromtimestamp(comment.created_utc),\n",
    "                                  comment.score,\n",
    "                                  match.group()]) # Add matched string to table\n",
    "        return pd.DataFrame(table, columns = ['post_id', 'comment_id', 'comment_text',\n",
    "                                              'subreddit', 'creation_datetime', 'comment_karma',\n",
    "                                              'matched_string'])\n",
    "    else:\n",
    "        subreddits = ['RandomTables','BehindTheTables','d100']\n",
    "        table = []\n",
    "        for subreddit in subreddits:\n",
    "            for submission in reddit.subreddit(subreddit).top(limit=post_limit, time_filter=timeframe):\n",
    "                comments = submission.comments[:-1] # not taking into account the MoreComments object\n",
    "                for comment in comments:\n",
    "                    match = re.search(r'\\b\\d+d\\d+\\b', comment.body) # Search for pattern\n",
    "                    if match:\n",
    "                        table.append([submission.id,\n",
    "                                      comment.id,\n",
    "                                      comment.body,\n",
    "                                      submission.subreddit.display_name,\n",
    "                                      datetime.datetime.utcfromtimestamp(comment.created_utc),\n",
    "                                      comment.score,\n",
    "                                      match.group()]) # Add matched string to table\n",
    "        return pd.DataFrame(table, columns = ['post_id', 'comment_id', 'comment_text',\n",
    "                                              'subreddit', 'creation_datetime', 'comment_karma',\n",
    "                                              'matched_string'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_reddit_data():\n",
    "    \"\"\"\n",
    "    Create reddit instance and collect data to write to gcs as two csv's,\n",
    "    one for posts, and the other for comments on those posts.\n",
    "    \"\"\"\n",
    "    reddit = praw_setup(client_id, client_secret, user_agent, password, username)\n",
    "    blob_name_posts = f'{yesterday}/posts.csv' # names for the files\n",
    "    blob_name_comments = f'{yesterday}/comments.csv'\n",
    "    \n",
    "    df_posts = get_post_titles_text_and_features(reddit, post_limit=1000, timeframe='week', one_sub=False, sub=None)\n",
    "    # df_comments = get_comments_and_features(reddit, post_limit=1000, timeframe='day', one_sub=False, sub=None)\n",
    "\n",
    "    return df_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _download_reddit_data_comments():\n",
    "    \"\"\"\n",
    "    Create reddit instance and collect data to write to gcs as two csv's,\n",
    "    one for posts, and the other for comments on those posts.\n",
    "    \"\"\"\n",
    "    reddit = praw_setup(client_id, client_secret, user_agent, password, username)\n",
    "    blob_name_posts = f'{yesterday}/posts.csv' # names for the files\n",
    "    blob_name_comments = f'{yesterday}/comments.csv'\n",
    "    \n",
    "    # df_posts = get_post_titles_text_and_features(reddit, post_limit=1000, timeframe='day', one_sub=False, sub=None)\n",
    "    df_comments = get_comments_and_features(reddit, post_limit=1000, timeframe='week', one_sub=False, sub=None)\n",
    "\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the post data\n",
    "df_post_1 = _download_reddit_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 score  num_comments  total_awards_received\n",
      "post_subreddit                                             \n",
      "BehindTheTables     58             1                      0\n",
      "DnD              12588          2301                      1\n",
      "RandomTables         2             0                      0\n",
      "d100               209            21                      0\n"
     ]
    }
   ],
   "source": [
    "# display which subreddit are the posts coming from \n",
    "print(df_post_1.groupby('post_subreddit').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    post_id                                         post_title  \\\n",
      "0   13337v6  Dungeons & Dragons: Honor Among Thieves Just B...   \n",
      "1   1351z82                This Anti-DM mentality has to stop.   \n",
      "2   12ysjjk         Why don't more tables use the Mark action?   \n",
      "3   133dpez                                      Thank your DM   \n",
      "4   134k8xg  I am giving English lessons and have played a ...   \n",
      "..      ...                                                ...   \n",
      "70   zz8m3k      Happy Cakeday, r/RandomTables! Today you're 8   \n",
      "71   ynylgw   Happy Cakeday, r/BehindTheTables! Today you're 7   \n",
      "72  133wwcj  D100 Epithets for Good Bosses (Priests, Paladi...   \n",
      "73  130nbon                           D20x5 Variegated Vikings   \n",
      "74  13488hd                    Rumors for an all-aquatic world   \n",
      "\n",
      "                                            post_text   post_subreddit  \\\n",
      "0   Looks like the D&D movie just made it past its...              DnD   \n",
      "1   So many comments always end the same way. \"The...              DnD   \n",
      "2   From the DMG pg 271,\\n\\n\"This option makes it ...              DnD   \n",
      "3   I've been playing D&D since 2010 or so, and in...              DnD   \n",
      "4   &#x200B;\\n\\n[The names of our characters and t...              DnD   \n",
      "..                                                ...              ...   \n",
      "70  Let's look back at some memorable moments and ...     RandomTables   \n",
      "71  Let's look back at some memorable moments and ...  BehindTheTables   \n",
      "72  Your priests, paladins and holy warriors servi...             d100   \n",
      "73  Apparently viking is a verb as well as a noun....             d100   \n",
      "74  Alright peeps. I need help. I've got this all-...             d100   \n",
      "\n",
      "     creation_datetime  score  num_comments  total_awards_received  \n",
      "0  2023-04-29 18:35:43  11464          1128                      1  \n",
      "1  2023-05-01 21:32:59    398           285                      0  \n",
      "2  2023-04-25 19:00:58    158           127                      0  \n",
      "3  2023-04-30 02:34:50     91            11                      0  \n",
      "4  2023-05-01 11:47:19     87            17                      0  \n",
      "..                 ...    ...           ...                    ...  \n",
      "70 2022-12-30 19:07:09      2             0                      0  \n",
      "71 2022-11-06 18:40:12     58             1                      0  \n",
      "72 2023-04-30 16:50:50    100             1                      0  \n",
      "73 2023-04-27 14:08:53     63            13                      0  \n",
      "74 2023-05-01 00:52:24     46             7                      0  \n",
      "\n",
      "[75 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# display the list of posts\n",
    "print(df_post_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>creation_datetime</th>\n",
       "      <th>comment_karma</th>\n",
       "      <th>matched_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_id, comment_id, comment_text, subreddit, creation_datetime, comment_karma, matched_string]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comment_1 = _download_reddit_data_comments()\n",
    "df_comment_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # save the post to csv and txt\n",
    "# df_post_1.to_csv('./data/table.csv')\n",
    "# df_post_1['post_text'].to_csv('./data/table_text_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cleaning the txt file \n",
    "\n",
    "# # open the input file\n",
    "# with open('./data/reddit_post_text.txt') as file:\n",
    "#     text = file.read()\n",
    "\n",
    "# # define a regular expression to match differnt patterns\n",
    "# pattern_https = re.compile(r'https?://\\S+') #HTTPS links\n",
    "# pattern_u = re.compile(r'\\s[uU]/\\w+|\\\\u|[\\(\\)\\[\\]/]u|u/') # u/123abc or [\\u] or (\\u) or /u\n",
    "\n",
    "\n",
    "# # remove all the HTTPS links from the text\n",
    "# text = re.sub(pattern_https, '', text)\n",
    "# text = re.sub(pattern_u, '', text)\n",
    "\n",
    "# # open the output file and write the modified text \n",
    "# with open('./data/reddit_post_text.txt', 'w') as file:\n",
    "#     file.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_csv_to_s3(bucket_name, object_name, aws_access_key_id, aws_secret_access_key, df):\n",
    "    '''\n",
    "    Write a dataframe (df) as a CSV file to S3 bucket.\n",
    "    '''\n",
    "    s3 = boto3.resource('s3',\n",
    "                        aws_access_key_id=aws_access_key_id,\n",
    "                        aws_secret_access_key=aws_secret_access_key)\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3.Object(bucket_name, object_name).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
